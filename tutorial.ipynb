{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: pymilvus[model]\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet pymilvus[model] langchain-milvus langchain-openai\n",
    "%pip install -qU langchain_community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_URI = \"http://localhost:19530\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_embedding_func = OllamaLLM(model=\"moondream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2303.05510v1.pdf']\n",
      "Vector store for 2303.05510v1.pdf created successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Ollama Setup\n",
    "def setup_ollama_pdf_vectorstore(file_path, embedding_model=\"moondream\"):\n",
    "    try:\n",
    "        # 1. Load PDF\n",
    "        loader = PyMuPDFLoader(file_path)\n",
    "        docs = loader.load()\n",
    "\n",
    "        # 2. Text Splitting (Optional but recommended)\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        splits = text_splitter.split_documents(docs)\n",
    "\n",
    "        # 3. Ollama Embeddings\n",
    "        embeddings = OllamaEmbeddings(\n",
    "            model=embedding_model,  # You can change this to other Ollama models\n",
    "            num_gpu=16  # Optional: specify GPU usage\n",
    "        )\n",
    "\n",
    "        # 4. Create Chroma Vector Store\n",
    "        vector_store = Chroma.from_documents(\n",
    "            documents=splits,\n",
    "            embedding=embeddings,\n",
    "            collection_name=\"ollama_pdf_collection\"\n",
    "        )\n",
    "\n",
    "        return vector_store\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "files = os.listdir(\"papers\")\n",
    "print(files)\n",
    "\n",
    "vector_store = setup_ollama_pdf_vectorstore(f\"papers/{files[0]}\")\n",
    "print(f\"Vector store for {files[0]} created successfully\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relevant Document Excerpt ---\n",
      "Published as a conference paper at ICLR 2023\n",
      "APPENDIX\n",
      "In this appendix, we supplement the main paper by providing more thorough empirical evaluations to\n",
      "back up our claims and more detailed descriptions of the algorithms to help readers better understand\n",
      "our paper.\n",
      "This appendix is organized as follows.\n",
      "• In Sec. A, we provide more comprehensive results of our algorithm and the baseline algorithms.\n",
      "We also include the license information of the datasets we use.\n",
      "• In Sec. B, we consider the scenario where test cases are not provided. We evaluate our PG-TD\n",
      "algorithm using automatically-generated test cases.\n",
      "• In Sec. C, we provide empirical evidence for our claims in the discussion section that our\n",
      "algorithm is versatile and can be used to optimize different code generation objectives other\n",
      "than the pass rate. We consider the objectives of generating concise codes and generating\n",
      "codes with more comments.\n",
      "\n",
      "--- Relevant Document Excerpt ---\n",
      "Published as a conference paper at ICLR 2023\n",
      "APPENDIX\n",
      "In this appendix, we supplement the main paper by providing more thorough empirical evaluations to\n",
      "back up our claims and more detailed descriptions of the algorithms to help readers better understand\n",
      "our paper.\n",
      "This appendix is organized as follows.\n",
      "• In Sec. A, we provide more comprehensive results of our algorithm and the baseline algorithms.\n",
      "We also include the license information of the datasets we use.\n",
      "• In Sec. B, we consider the scenario where test cases are not provided. We evaluate our PG-TD\n",
      "algorithm using automatically-generated test cases.\n",
      "• In Sec. C, we provide empirical evidence for our claims in the discussion section that our\n",
      "algorithm is versatile and can be used to optimize different code generation objectives other\n",
      "than the pass rate. We consider the objectives of generating concise codes and generating\n",
      "codes with more comments.\n",
      "\n",
      "--- Relevant Document Excerpt ---\n",
      "Published as a conference paper at ICLR 2023\n",
      "Pass Rate (%)\n",
      "Strict Accuracy (%)\n",
      "APPS Intro.\n",
      "APPS Inter.\n",
      "APPS comp.\n",
      "CodeContests\n",
      "APPS Intro.\n",
      "APPS Inter.\n",
      "APPS comp.\n",
      "CodeContests\n",
      "APPS GPT-2\n",
      "Beam Search\n",
      "11.95\n",
      "9.55\n",
      "5.04\n",
      "5.10\n",
      "5.50\n",
      "2.10\n",
      "1.00\n",
      "0.00\n",
      "Sampling+Filtering\n",
      "25.19\n",
      "24.13\n",
      "11.92\n",
      "20.40\n",
      "13.80\n",
      "5.70\n",
      "2.30\n",
      "3.64\n",
      "SMCG-TD\n",
      "24.10\n",
      "21.98\n",
      "10.37\n",
      "17.47\n",
      "11.70\n",
      "5.50\n",
      "2.10\n",
      "4.24\n",
      "PG-TD (c = 4)\n",
      "26.70\n",
      "24.92\n",
      "12.89\n",
      "24.05\n",
      "13.10\n",
      "6.10\n",
      "3.10\n",
      "4.85\n",
      "APPS GPT-Neo\n",
      "Beam Search\n",
      "14.32\n",
      "9.80\n",
      "6.39\n",
      "5.73\n",
      "6.70\n",
      "2.00\n",
      "2.10\n",
      "0.00\n",
      "Sampling+Filtering\n",
      "27.71\n",
      "24.85\n",
      "12.55\n",
      "25.26\n",
      "15.50\n",
      "5.80\n",
      "3.00\n",
      "4.24\n",
      "SMCG-TD\n",
      "25.09\n",
      "20.34\n",
      "9.16\n",
      "15.44\n",
      "13.80\n",
      "5.10\n",
      "1.80\n",
      "3.03\n",
      "PG-TD (c = 4)\n",
      "29.27\n",
      "25.69\n",
      "13.55\n",
      "26.07\n",
      "15.50\n",
      "6.43\n",
      "3.50\n",
      "4.85\n",
      "Table 1: Results of PG-TD and other algorithms. The maximum number of Transformer generations\n",
      "for all algorithms is 256.\n",
      "200\n",
      "400\n",
      "600\n",
      "# of Transformer Generations\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Computation Time (sec.)\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "SMCG-TD\n",
      "Sampling + Filtering\n",
      "PG-TD (c = 2)\n",
      "PG-TD (c = 4)\n",
      "PG-TD (c = 6)\n",
      "\n",
      "--- Relevant Document Excerpt ---\n",
      "Published as a conference paper at ICLR 2023\n",
      "Pass Rate (%)\n",
      "Strict Accuracy (%)\n",
      "APPS Intro.\n",
      "APPS Inter.\n",
      "APPS comp.\n",
      "CodeContests\n",
      "APPS Intro.\n",
      "APPS Inter.\n",
      "APPS comp.\n",
      "CodeContests\n",
      "APPS GPT-2\n",
      "Beam Search\n",
      "11.95\n",
      "9.55\n",
      "5.04\n",
      "5.10\n",
      "5.50\n",
      "2.10\n",
      "1.00\n",
      "0.00\n",
      "Sampling+Filtering\n",
      "25.19\n",
      "24.13\n",
      "11.92\n",
      "20.40\n",
      "13.80\n",
      "5.70\n",
      "2.30\n",
      "3.64\n",
      "SMCG-TD\n",
      "24.10\n",
      "21.98\n",
      "10.37\n",
      "17.47\n",
      "11.70\n",
      "5.50\n",
      "2.10\n",
      "4.24\n",
      "PG-TD (c = 4)\n",
      "26.70\n",
      "24.92\n",
      "12.89\n",
      "24.05\n",
      "13.10\n",
      "6.10\n",
      "3.10\n",
      "4.85\n",
      "APPS GPT-Neo\n",
      "Beam Search\n",
      "14.32\n",
      "9.80\n",
      "6.39\n",
      "5.73\n",
      "6.70\n",
      "2.00\n",
      "2.10\n",
      "0.00\n",
      "Sampling+Filtering\n",
      "27.71\n",
      "24.85\n",
      "12.55\n",
      "25.26\n",
      "15.50\n",
      "5.80\n",
      "3.00\n",
      "4.24\n",
      "SMCG-TD\n",
      "25.09\n",
      "20.34\n",
      "9.16\n",
      "15.44\n",
      "13.80\n",
      "5.10\n",
      "1.80\n",
      "3.03\n",
      "PG-TD (c = 4)\n",
      "29.27\n",
      "25.69\n",
      "13.55\n",
      "26.07\n",
      "15.50\n",
      "6.43\n",
      "3.50\n",
      "4.85\n",
      "Table 1: Results of PG-TD and other algorithms. The maximum number of Transformer generations\n",
      "for all algorithms is 256.\n",
      "200\n",
      "400\n",
      "600\n",
      "# of Transformer Generations\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Computation Time (sec.)\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "SMCG-TD\n",
      "Sampling + Filtering\n",
      "PG-TD (c = 2)\n",
      "PG-TD (c = 4)\n",
      "PG-TD (c = 6)\n",
      "\n",
      "--- Relevant Document Excerpt ---\n",
      "Published as a conference paper at ICLR 2023\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "# of Transformer Generations\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Computation Time (sec.)\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "SMCG-TD\n",
      "Sampling + Filtering\n",
      "PG-TD (b = 1)\n",
      "PG-TD (b = 3)\n",
      "PG-TD (b = 5)\n",
      "Figure 5: Results of PG-TD (c = 2) on the APPS introductory dataset, using the APPS GPT-2\n",
      "Transformer model.\n",
      "200\n",
      "400\n",
      "# of Transformer Generations\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Computation Time (sec.)\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "SMCG-TD\n",
      "Sampling + Filtering\n",
      "PG-TD (b = 1)\n",
      "PG-TD (b = 3)\n",
      "PG-TD (b = 5)\n",
      "Figure 6: Results of PG-TD (c = 4) on the APPS introductory dataset, using the APPS GPT-2\n",
      "Transformer model.\n",
      "200\n",
      "400\n",
      "# of Transformer Generations\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "Computation Time (sec.)\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "PG-TD (k = 2)\n",
      "PG-TD (k = 3)\n",
      "PG-TD (k = 4)\n",
      "Figure 7: Results of PG-TD (c = 4) with different k on the APPS introductory dataset, using the\n",
      "APPS GPT-2 Transformer model..\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "\n",
      "--- Relevant Document Excerpt ---\n",
      "Published as a conference paper at ICLR 2023\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "# of Transformer Generations\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Computation Time (sec.)\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "SMCG-TD\n",
      "Sampling + Filtering\n",
      "PG-TD (b = 1)\n",
      "PG-TD (b = 3)\n",
      "PG-TD (b = 5)\n",
      "Figure 5: Results of PG-TD (c = 2) on the APPS introductory dataset, using the APPS GPT-2\n",
      "Transformer model.\n",
      "200\n",
      "400\n",
      "# of Transformer Generations\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Computation Time (sec.)\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "SMCG-TD\n",
      "Sampling + Filtering\n",
      "PG-TD (b = 1)\n",
      "PG-TD (b = 3)\n",
      "PG-TD (b = 5)\n",
      "Figure 6: Results of PG-TD (c = 4) on the APPS introductory dataset, using the APPS GPT-2\n",
      "Transformer model.\n",
      "200\n",
      "400\n",
      "# of Transformer Generations\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "Computation Time (sec.)\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "Pass Rate (%)\n",
      "PG-TD (k = 2)\n",
      "PG-TD (k = 3)\n",
      "PG-TD (k = 4)\n",
      "Figure 7: Results of PG-TD (c = 4) with different k on the APPS introductory dataset, using the\n",
      "APPS GPT-2 Transformer model..\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "\n",
      "--- Relevant Document Excerpt ---\n",
      "test cases to verify the generated programs.\n",
      "C\n",
      "PLANNING FOR OTHER CODE GENERATION OBJECTIVES\n",
      "Besides the default reward function that optimizes the pass rate, we show the versatility of the pro-\n",
      "posed algorithm by setting two new objectives, code length penalty and comment encouragement.\n",
      "Code length penalty. We make the planner generate more concise codes by using the following\n",
      "reward function\n",
      "Rlength = p + λ1 × e−lc/t,\n",
      "(1)\n",
      "where p is the average pass rate on the public test case set and lc is the length of the code string. λ\n",
      "and t are hyperparameters that control the weight of the code length penalty and are set to 0.1 and\n",
      "20, respectively. As shown in Figure 9, the generated solution becomes more concise and the code\n",
      "string length decreases from 187 to 78 while still passing all the test cases.\n",
      "Comment encouragement. We can also generate solutions with more comments. We achieve this\n",
      "goal by using the following reward function\n",
      "Rcomment = p + λ1 × e−lc/t + λ2 × min(1, Ncm\n",
      "Nmax\n",
      "),\n",
      "(2)\n",
      "\n",
      "--- Relevant Document Excerpt ---\n",
      "test cases to verify the generated programs.\n",
      "C\n",
      "PLANNING FOR OTHER CODE GENERATION OBJECTIVES\n",
      "Besides the default reward function that optimizes the pass rate, we show the versatility of the pro-\n",
      "posed algorithm by setting two new objectives, code length penalty and comment encouragement.\n",
      "Code length penalty. We make the planner generate more concise codes by using the following\n",
      "reward function\n",
      "Rlength = p + λ1 × e−lc/t,\n",
      "(1)\n",
      "where p is the average pass rate on the public test case set and lc is the length of the code string. λ\n",
      "and t are hyperparameters that control the weight of the code length penalty and are set to 0.1 and\n",
      "20, respectively. As shown in Figure 9, the generated solution becomes more concise and the code\n",
      "string length decreases from 187 to 78 while still passing all the test cases.\n",
      "Comment encouragement. We can also generate solutions with more comments. We achieve this\n",
      "goal by using the following reward function\n",
      "Rcomment = p + λ1 × e−lc/t + λ2 × min(1, Ncm\n",
      "Nmax\n",
      "),\n",
      "(2)\n",
      "\n",
      "--- Relevant Document Excerpt ---\n",
      "Published as a conference paper at ICLR 2023\n",
      "Problem Statement\n",
      "Given is an integer r. How many times is the area of a circle of radius r larger than the area\n",
      "of a circle of radius 1? It can be proved that the answer is always an integer under the constraints\n",
      "given.\n",
      "Constraints\n",
      "(1). 1 ≤r ≤100.\n",
      "(2). All values in input are integers.\n",
      "Input\n",
      "Input is given from Standard Input in the following format: r.\n",
      "Output\n",
      "Print the area of a circle of radius r, divided by the area of a circle of radius 1, as an integer..\n",
      "Sample Test Input\n",
      "2\n",
      "Sample Test Output\n",
      "4\n",
      "The area of a circle of radius 2 is 4 times larger than the area of a circle of radius 1. Note that\n",
      "output must be an integer - for example, 4.0 will not be accepted.\n",
      "1\n",
      "# cook your dish here\n",
      "2\n",
      "r=int(input())\n",
      "3\n",
      "if(r>=2*r):\n",
      "4\n",
      "print(r*r*2)\n",
      "5\n",
      "else:\n",
      "6\n",
      "print(0)\n",
      "Beam Search (Pass Rate: 0.00).\n",
      "1\n",
      "# cook your dish here\n",
      "2\n",
      "r=int(input())\n",
      "3\n",
      "if(r>=2*r):\n",
      "4\n",
      "print(r*r*2)\n",
      "5\n",
      "else:\n",
      "6\n",
      "print(0)\n",
      "Sampling + Filtering (Pass Rate:\n",
      "0.00).\n",
      "1\n",
      "# cook your dish here\n",
      "2\n",
      "\n",
      "--- Relevant Document Excerpt ---\n",
      "Transformer model, we run beam search to generate solutions on the test set to see if it has a better\n",
      "performance. We use the ﬁrst 500 problems in the interview-level problems in APPS test set for\n",
      "validation and the introductory-level problems in APPS test set for testing. The results are reported\n",
      "in Table 3. After ﬁnetuning with PG-TD-generated solutions, we see improvement in both pass rate\n",
      "and strict accuracy. More details are in Sec. D.4.\n",
      "Methods\n",
      "Code ↓\n",
      "Comment ↑\n",
      "Pass ↑\n",
      "length\n",
      "number\n",
      "rate\n",
      "Default\n",
      "248.42\n",
      "0.68\n",
      "23.14\n",
      "Length Penalty\n",
      "190.73\n",
      "-\n",
      "22.82\n",
      "Comment Encouragement\n",
      "-\n",
      "3.11\n",
      "21.65\n",
      "Table 4: Performance of controllable code generation.\n",
      "Code length denotes the length of the generated code\n",
      "string and comment number denotes the number of code\n",
      "lines that contains comments.\n",
      "Optimizing other code generation\n",
      "objectives.\n",
      "Beyond the pass rate,\n",
      "we can make the algorithm versatile\n",
      "by using different reward functions.\n",
      "We consider two new objectives, code\n",
      "length penalty and comment encour-\n",
      "agement.\n"
     ]
    }
   ],
   "source": [
    "# Perform Similarity Search\n",
    "contexts = \"\"\n",
    "query = input(\"Enter your query: \")\n",
    "\n",
    "if vector_store:\n",
    "    results = vector_store.similarity_search(query, k=10)\n",
    "    \n",
    "    for doc in results:\n",
    "        print(\"\\n--- Relevant Document Excerpt ---\")\n",
    "        print(doc.page_content)\n",
    "        contexts = contexts + doc.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ollama Response ---\n",
      "The text describes a software tool for generating code solutions to specific problems in an interview setting, called \"prophet\". Here's a breakdown of the key points:\n",
      "\n",
      "**Problem Statement**\n",
      "\n",
      "Prophet aims to generate solutions to problems from standard input (integer values) using a combination of natural language and mathematical reasoning. The goal is to produce solutions that meet certain constraints, such as passing certain tests or having an integer output.\n",
      "\n",
      "**Input/Output**\n",
      "\n",
      "* Input: Integer values on standard input\n",
      "* Output: String representations of generated code solutions with specific formatting\n",
      "\n",
      "**Features**\n",
      "\n",
      "* Optimized for performance using various techniques (e.g., beam search)\n",
      "* Can generate solutions from problem inputs in multiple formats (e.g., pass rate, strict accuracy)\n",
      "\n",
      "**Methodology**\n",
      "\n",
      "1. **Problem Definition**: Problem description and constraints are provided.\n",
      "2. **Input Processing**: Input values are processed to ensure they meet the specified constraints.\n",
      "3. **Code Generation**: A solution is generated using a combination of natural language and mathematical reasoning.\n",
      "4. **Post-processing**: Code solutions are formatted according to specific requirements.\n",
      "\n",
      "**Performance**\n",
      "\n",
      "* Results are reported in various tables, including:\n",
      "\t+ Performance metrics (e.g., pass rate, strict accuracy)\n",
      "\t+ Comparison with original solutions\n",
      "\t+ Comparison with other code generation tools\n",
      "\n",
      "**Improvements**\n",
      "\n",
      "* Fine-tuning of the model using Prophet-generated solutions\n",
      "* Evaluation of optimization techniques beyond pass rate\n",
      "\n",
      "**Objectives**\n",
      "\n",
      "Prophet aims to:\n",
      "\n",
      "1. **Improve Performance**: Enhance the tool's ability to generate high-quality solutions.\n",
      "2. **Increase Flexibility**: Introduce new reward functions and objectives to make the algorithm more versatile.\n",
      "\n",
      "The text concludes by highlighting the versatility of Prophet, with two new objective functions (code length penalty and comment encouragement) that can be used to improve its performance and flexibility.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize Ollama Chat Model\n",
    "chat_model = ChatOllama(\n",
    "    model=\"llama3.2:1b\",  # You can change to other models like mistral, phi3\n",
    "    temperature=0.7,  # Creativity level\n",
    "    num_gpu=16  # Optional GPU configuration\n",
    ")\n",
    "\n",
    "# Simple Chat Interaction\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant for my research.\"),\n",
    "    HumanMessage(content= f\"Query + {query} with the context + {contexts}\")\n",
    "]\n",
    "\n",
    "# Generate Response\n",
    "response = chat_model.invoke(messages)\n",
    "print(\"--- Ollama Response ---\")\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
