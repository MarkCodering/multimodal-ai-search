{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_URI = \"http://localhost:19530\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_embedding_func = OllamaLLM(model=\"moondream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2303.05510v1.pdf']\n",
      "Vector store for 2303.05510v1.pdf created successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Ollama Setup\n",
    "def setup_ollama_pdf_vectorstore(file_path, embedding_model=\"moondream\"):\n",
    "    try:\n",
    "        # 1. Load PDF\n",
    "        loader = PyMuPDFLoader(file_path)\n",
    "        docs = loader.load()\n",
    "\n",
    "        # 2. Text Splitting (Optional but recommended)\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        splits = text_splitter.split_documents(docs)\n",
    "\n",
    "        # 3. Ollama Embeddings\n",
    "        embeddings = OllamaEmbeddings(\n",
    "            model=embedding_model,  # You can change this to other Ollama models\n",
    "            num_gpu=16  # Optional: specify GPU usage\n",
    "        )\n",
    "\n",
    "        # 4. Create Chroma Vector Store\n",
    "        vector_store = Chroma.from_documents(\n",
    "            documents=splits,\n",
    "            embedding=embeddings,\n",
    "            collection_name=\"ollama_pdf_collection\"\n",
    "        )\n",
    "\n",
    "        return vector_store\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "files = os.listdir(\"papers\")\n",
    "print(files)\n",
    "\n",
    "vector_store = setup_ollama_pdf_vectorstore(f\"papers/{files[0]}\")\n",
    "print(f\"Vector store for {files[0]} created successfully\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relevant Document Excerpt ---\n",
      "function. To evaluate the quality of the automatically-generated test cases, we compute the strict\n",
      "accuracies of the sample solutions (correct solutions written by human programmers) on these test\n",
      "cases. Clearly, the strict accuracies of the sample solutions on the ground-truth test cases should\n",
      "be 100%. We evaluate the sample solutions on the automatically-generated test cases and ﬁnd the\n",
      "corresponding strict accuracy is 72.56%, which conﬁrms that the automatically-generated test cases\n",
      "are mostly correct.\n",
      "Can PG-TD take advantage of the automatically-generated test cases? We report the average\n",
      "strict accuracy of the generated programs on a subset of HumanEval problems in Table 11. We\n",
      "conﬁrm that the strict accuracy of PG-TD is higher as it uses high-quality automatically-generated\n",
      "test cases to verify the generated programs.\n",
      "C\n",
      "PLANNING FOR OTHER CODE GENERATION OBJECTIVES\n",
      "Besides the default reward function that optimizes the pass rate, we show the versatility of the pro-\n",
      "\n",
      "--- Relevant Document Excerpt ---\n",
      "Published as a conference paper at ICLR 2023\n",
      "Finetuning transformer with PG-TD-generated samples. Since we are able to generate solutions\n",
      "with high pass rates using our PG-TD algorithm, can we use these generated solutions to ﬁnetune\n",
      "the code generation Transformers to further improve their performance? This may effectively solve\n",
      "the problem that high-quality human-written programs that can be used to train the code generation\n",
      "Transformers are scarcely available. Concretely, we ﬁrst run PG-TD on the training set of APPS.\n",
      "We then add the generated solutions with pass rates larger than 80% to the APPS sample solution\n",
      "set, and use the augmented solution set to ﬁnetune the GPT-2 (2.7B) model. With the ﬁnetuned\n",
      "Transformer model, we run beam search to generate solutions on the test set to see if it has a better\n",
      "performance. We use the ﬁrst 500 problems in the interview-level problems in APPS test set for\n",
      "\n",
      "--- Relevant Document Excerpt ---\n",
      "Published as a conference paper at ICLR 2023\n",
      "Problem Statement\n",
      "You are given an array a consisting of n integer numbers.\n",
      "Let instability of the array be the following value:\n",
      "n\n",
      "max\n",
      "i=1 ai −\n",
      "n\n",
      "min\n",
      "i=1 ai.\n",
      "You have to remove exactly one element from this array to minimize instability of the resulting\n",
      "(n −1)-elements array. Your task is to calculate the minimum possible instability.\n",
      "Input\n",
      "The ﬁrst line of the input contains one integer n (2 ≤n ≤105) — the number of elements in the\n",
      "array a.\n",
      "The second line of the input contains n integers a1, a2, . . . , an (1 ≤ai ≤105) — elements of the\n",
      "array a.\n",
      "Output\n",
      "Print one integer — the minimum possible instability of the array if you have to remove exactly one\n",
      "element from the array a.\n",
      "Examples\n",
      "Input\n",
      "4\n",
      "1 3 3 7\n",
      "Output\n",
      "2\n",
      "Input\n",
      "2\n",
      "1 100000\n",
      "Output\n",
      "0\n",
      "Note\n",
      "In the ﬁrst example you can remove 7 then instability of the remaining array will be 3 −1 = 2.\n",
      "In the second example you can remove either 1 or 100000 then instability of the remaining array\n"
     ]
    }
   ],
   "source": [
    "# Perform Similarity Search\n",
    "contexts = \"\"\n",
    "query = input(\"Enter your query: \")\n",
    "\n",
    "if vector_store:\n",
    "    results = vector_store.similarity_search(query, k=3)\n",
    "    \n",
    "    for doc in results:\n",
    "        print(\"\\n--- Relevant Document Excerpt ---\")\n",
    "        print(doc.page_content)\n",
    "        contexts = contexts + doc.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ollama Response ---\n",
      "Based on the provided text, here are three potential research ideas for this problem:\n",
      "\n",
      "1. **Investigating the Effectiveness of PG-TD-generated Test Cases in Code Generation**: Building upon the success of using automatically-generated test cases to evaluate code generation algorithms like PG-TD, this research could explore whether these test cases can be effectively used as input to fine-tune transformer models for improved performance. This might involve analyzing the impact of different types of test cases (e.g., error-free vs. noisy) on the generated solutions and their ability to improve the model's performance.\n",
      "\n",
      "2. **Analyzing the Impact of Automatically-Generated Test Cases on Code Generation Optimization Algorithms**: Given that PG-TD generates high-quality test cases, this research could investigate how these test cases affect optimization algorithms for code generation tasks. For example, it might examine whether using automatically-generated test cases can lead to better exploration of the solution space, reduced overfitting, or improved convergence rates during model training.\n",
      "\n",
      "3. **Developing and Evaluating New Optimization Algorithms for Code Generation Tasks**: Combining insights from PG-TD's strengths in generating high-quality test cases with existing optimization algorithms, this research could aim to develop new approaches that leverage these test cases to optimize code generation tasks more effectively. This might involve exploring different optimization techniques (e.g., gradient-based methods, evolutionary algorithms) and evaluating their performance on various code generation tasks.\n",
      "\n",
      "These ideas build upon the strengths of PG-TD and auto-generated test cases while offering opportunities for exploration and innovation in areas such as fine-tuning transformer models, optimizing code generation algorithms, or developing new optimization approaches.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize Ollama Chat Model\n",
    "chat_model = ChatOllama(\n",
    "    model=\"llama3.2:1b\",  # You can change to other models like mistral, phi3\n",
    "    temperature=0.7,  # Creativity level\n",
    ")\n",
    "\n",
    "# Simple Chat Interaction\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant for my research.\"),\n",
    "    HumanMessage(content=f\"Query + {query} with the context + {contexts}\")\n",
    "]\n",
    "\n",
    "# Generate Response\n",
    "response = chat_model.invoke(messages)\n",
    "print(\"--- Ollama Response ---\")\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
